# base working directory or directories for the project
# each directory found in one of these paths is treated like a collection
wrk_dirs:
  - /opt/migrations/client/cdm
  - /opt/migrations/client/omeka

# path to logfile
logfile: /opt/migrations/client/mdmm.log

# do not compile data/stats/reports on field values or types for field names beginning with (or equaling)
#  any of the following
reporting_ignore_field_prefixes:
  - cdmfilesize
  - dm
  - migchildptrs
  - migchilddata
  - restrictionCode

fieldvalues_file: /opt/migrations/client/_fieldvalues.csv

# do not perform cleanup operations on field values in fields with names that begin with (or equal) any
#   of the following
cleanup_ignore_field_prefixes:
  - mig
  - dm
  - fullrs
  - find
  - restrictionCode

# do not perform metadata mapping on fields with names that begin with (or equal) any
#   of the following
mapping_ignore_field_prefixes:
  - mig
  - dm
  - fullrs
  - find
  - restrictionCode

# list of fields to process as dates
# special cleanup and mappings are done on dates
date_fields:
  - date
  - publis
  
# full path to mappings csv in the following format
#   collectionName,fieldname,mappingsnippet
mappings: '/opt/migrations/client/mappings.csv'

# fix things that break the initial splitting and remapping processes
prelim_replacements:
    # non-breaking space
  - colls: ''
    fields: ''
    find: "\u00A0"
    replace: ' '
    type: plain

# replacements that introduce standard and non-ambiguous delimiters in multivalued fields
splits:
  # split multivalued on ' and '
  - colls:
      - coll1
      - coll2
    fields:
      - author
    find: ' and '
    replace: ';;;'
    type: plain
  # split multivalued on ';'
  - colls: ''
    fields:
      - author
      - identifier
      - subject
    find: ';'
    replace: ';;;'
    type: plain
    # split descriptions on line breaks because of more complex formatting
  - colls: ''
    fields: 'description'
    find: '<br *\/> *<br *\/>'
    replace: ';;;'
    type: regexp

# configure the addition of constant values
constant_fields:
  - colls: ''
    field: recsourceorg
    value: valueOfMARCOrgCode
  - colls: 
      - omekaColl1
      - omekaColl2
    field: sourcesystem
    value: Omeka
  - colls:
      - cdmColl1
      - cdmColl2
    field: sourcesystem
    value: CONTENTdm
    
# collections/fields in which to standardize first-character case
# mainly used for fields that will populate facets, to minimize split/near-duplicate
#  facets due to case differences
case_changes:  
  - colls: ''
    fields:
       - subject
       - format
    case: upper

# Map a field value to a different field based on field content
# Moves the field value to new field.
# If this leaves old field empty, old field is removed from cleaned record.
# condition value is turned into regular expression by default. This means:
#  '.' will match any character
#  '\.' will match literal period
move_fields:
  - colls: ''
    fields: coverage
    moveto: coveragegeog
    condition: 'United States'
  - colls: ''
    fields: type
    moveto: format
    condition: '^[Ss]peech$'

# Moves a field value to another field and replaces it in original field with a different value.
# For example, the type field may contain terms like drawings, paintings, photos
# You may want to move those values to the format field and replace them in type with "still image"
# colls = which collections the edit should be applied to (all if blank)
# fields = which original/current fields should be examined/treated
# condition = perform the move-and-replace if this matches original/current field value.
# moveto = matching value will be moved to this field
# replace = this value will be added to original/current field
move_and_replaces:
  - colls: ''
    fields: type
    condition: '^[Mm]ap'
    moveto: format
    replacewith: 'cartographic'

# Adds a value to derivefield based on field, but does not change source field value
derive_fields:
  - colls: ''
    fields: format
    condition: '[Pp]hotograph|JPEG'
    derivefield: type
    derivevalue: 'still image'
    
# Match part of one field and put the matching string into another field
# fields = the field(s) to match in/extract FROM
# condition = the value to match on (as a regexp)
# extracttofield = field the extracted value will be added to
# extractmatch = capture group/match segment that will be added to extracttofield
extractions:
  - colls: ''
    fields: reposa
    condition: 'at: (http.*)$'
    extracttofield: hostcolllink
    extractmatch: 1
    
# string replacements to be done
# if `colls` or `fields` are left blank, replacement will be done on all fields
# if the find string is just a literal string match, `type` = plain. `.` will be matched as a period, etc.
# if the find string is a regular expression, `type` = regexp. `.` will be matched as any character, etc.
#  NOTE: the surrounding // are NOT included in regexp find strings. 
replacements:
 # unicode replacement character
  - colls: ''
    fields: 'creato'
    find: "ï¿½"
    replace: "'"
    type: plain
  # delete HTML
  - colls: ''
    fields: ''
    find: '<\/?(br|div|em|p|span|strong|sup) *\/*>'
    replace: ' '
    type: regexp
    
